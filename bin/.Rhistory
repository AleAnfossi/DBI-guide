# Open a connection to a text file
sink("Diabetes_type1_info.txt")
# Print the result
print(highest_DBI_result)
# Print cardinality proportions
print(cardinality_proportions)
# Print the information
print(extracted_info)
# Close the connection
sink()
# Add name for saving!! This is the data csv print
write.csv(labels, file="Diabetes_type1+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="Diabetes_type1_DBI.csv")
source("~/GitHub/DBI-guide/bin/Diabetes.R")
source("~/GitHub/DBI-guide/bin/compare_clusterings.R")
#Script where I load an EHRs document(diabetes_type1) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#Loading data
mydata<-read.csv("diabetes_type1.csv")
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 25               #radius
minPts<-2             #minimal number of neighbours
#Setting the case
case <- "Diabetes"
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts,case)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Plot the result
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
#Exctract information DBI uses
extracted_info <- extract_clustering_info(mydata, labels)
# Open a connection to a text file
sink("Diabetes_type1_info.txt")
# Print the result
print(highest_DBI_result)
# Print cardinality proportions
print(cardinality_proportions)
# Print the information
print(extracted_info)
# Close the connection
sink()
# Add name for saving!! This is the data csv print
write.csv(labels, file="Diabetes_type1+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="Diabetes_type1_DBI.csv")
# Number of dimensions
dim <- 200      # <------
# Number of vectors
n <- 50        # <------
num <- 2 * n
# Creating the initial dataset, vectors are rows
zeros <- matrix(0, ncol = dim, nrow = num / 2)
ones <- matrix(1, ncol = dim, nrow = num / 2)
data <- rbind(zeros, ones)
# Initial kmeans and Davies-Bouldin index calculation
kmeans_result <- kmeans(data, centers = 2)
db_indices <- data.frame(t(DBI(data, kmeans_result$cluster)))
# Store the metrics
metrics <- extract_cluster_metrics(data, kmeans_result$cluster)
metrics_store <- data.frame(
Step = 0,
metrics
)
# Store the results
results <- data.frame(
Step = 0,
DB_Index_Avg = db_indices$average,
DB_Index_Centroid = db_indices$centroid,
Norm_DB_Index_Avg = db_indices$norm_ave,
Norm_DB_Index_Centroid = db_indices$norm_cent
)
# Store the data
data_store <- data.frame(
Step = 0,
data
)
# Store k-means results with vectors
kmeans_store <- data.frame(
Step = 0,
Cluster = kmeans_result$cluster,
data
)
# Function to generate a random vector in the given dimension
random_vector <- function() {
runif(dim, 0, 1)
}
# Modify vectors in a cyclic manner
for (i in 1:num) {
# Alternating cluster modified
if (i %% 2 == 1) {
data[(i + 1) / 2, ] <- random_vector()
} else {
data[n + i / 2, ] <- random_vector()
}
# kmeans and DBI execution at each step
kmeans_result <- kmeans(data, centers = 2, iter.max = 50 + i)
db_indices <- data.frame(t(DBI(data, kmeans_result$cluster)))
# Store results
results <- rbind(results, data.frame(
Step = i,
DB_Index_Avg = db_indices$average,
DB_Index_Centroid = db_indices$centroid,
Norm_DB_Index_Avg = db_indices$norm_ave,
Norm_DB_Index_Centroid = db_indices$norm_cent
))
# Store data
data_store <- rbind(data_store, data.frame(
Step = i,
data
))
# Store k-means results with vectors
kmeans_store <- rbind(kmeans_store, data.frame(
Step = i,
Cluster = kmeans_result$cluster,
data
))
# Store metrics
metrics <- extract_cluster_metrics(data, kmeans_result$cluster)
metrics_store <- rbind(metrics_store, data.frame(
Step = i,
metrics
))
# Hierarchical clustering and DBI calculation
hclust_results <- hclust_labels(data)
for (method in colnames(hclust_results)) {
hclust_db_indices <- data.frame(t(DBI(data, hclust_results[[method]])))
# Store results for hierarchical clustering
results <- rbind(results, data.frame(
Step = i,
DB_Index_Avg = hclust_db_indices$average,
DB_Index_Centroid = hclust_db_indices$centroid,
Norm_DB_Index_Avg = hclust_db_indices$norm_ave,
Norm_DB_Index_Centroid = hclust_db_indices$norm_cent
))
}
}
results$Step <- as.numeric(results$Step)
results$DB_Index_Avg <- as.numeric(results$DB_Index_Avg)
results$DB_Index_Centroid <- as.numeric(results$DB_Index_Centroid)
results$Norm_DB_Index_Avg <- as.numeric(results$Norm_DB_Index_Avg)
results$Norm_DB_Index_Centroid <- as.numeric(results$Norm_DB_Index_Centroid)
# Create the individual plots
plot1 <- ggplot(results, aes(x = Step, y = DB_Index_Avg)) +
geom_line() +
geom_point() +
scale_y_continuous(breaks = scales::pretty_breaks(n = 5), labels = scales::number_format(accuracy = 0.5)) +
ggtitle("DB Index Average over Steps") +
xlab("Step") +
ylab("DBI") +
theme_grey()
# Plot for DB_Index_Centroid
plot2 <- ggplot(results, aes(x = Step, y = DB_Index_Centroid)) +
geom_line() +
geom_point() +
scale_y_continuous(breaks = scales::pretty_breaks(n = 5), labels = scales::number_format(accuracy = 0.5)) +
ggtitle("DB Index Centroid over Steps") +
xlab("Step") +
ylab("DBI") +
theme_grey()
# Plot for Norm_DB_Index_Avg
plot3 <- ggplot(results, aes(x = Step, y = Norm_DB_Index_Avg)) +
geom_line() +
geom_point() +
scale_y_continuous(breaks = scales::pretty_breaks(n = 5), labels = scales::number_format(accuracy = 0.5)) +
ggtitle("Normalized DB Index Average over Steps") +
xlab("Step") +
ylab("DBI") +
theme_grey()
# Plot for Norm_DB_Index_Centroid
plot4 <- ggplot(results, aes(x = Step, y = Norm_DB_Index_Centroid)) +
geom_line() +
geom_point() +
scale_y_continuous(breaks = scales::pretty_breaks(n = 5), labels = scales::number_format(accuracy = 0.5)) +
ggtitle("Normalized DB Index Centroid over Steps") +
xlab("Step") +
ylab("DBI") +
theme_grey()
# Arrange the plots together
grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)
installed_packages <- installed.packages()[, "Package"]
for (pkg in installed_packages) { suppressPackageStartupMessages(library(pkg, character.only = TRUE)) }
installed_packages <- installed.packages()[, "Package"]
for (pkg in installed_packages) { suppressPackageStartupMessages(library(pkg, character.only = TRUE)) }
library(translations, lib.loc = "C:/Program Files/R/R-4.3.3/library")
source("~/GitHub/DBI-guide/bin/Diabetes.R")
#Script where I load an EHRs document(diabetes_type1) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#Loading data
mydata<-read.csv("diabetes_type1.csv")
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 25               #radius
minPts<-2             #minimal number of neighbours
#Setting the case
case <- "Diabetes"
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts,case)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Plot the result
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
#Exctract information DBI uses
extracted_info <- extract_clustering_info(mydata, labels)
# Open a connection to a text file
sink("Diabetes_type1_info.txt")
# Print the result
print(highest_DBI_result)
# Print cardinality proportions
print(cardinality_proportions)
# Print the information
print(extracted_info)
# Close the connection
sink()
# Add name for saving!! This is the data csv print
write.csv(labels, file="Diabetes_type1+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="Diabetes_type1_DBI.csv")
#Script where I load an EHRs document(depression_heart_failure) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#I had to get rid of id column since it didnt make any sense with the clustering
#Loading data
mydata0<-read.csv("depression_heart_failure.csv")
#Getting rid of id column
mydata<-mydata0[,2:ncol(mydata0)]
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 50              #radius
minPts<-10            #minimal number of neighbours
#Setting the case
case <- "Heart_failure"
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts,case)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Plot the result
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
#Exctract information DBI uses
extracted_info <- extract_clustering_info(mydata, labels)
# Open a connection to a text file
sink("Depression_Heart_Failure_info.txt")
# Print the result
print(highest_DBI_result)
# Print cardinality proportions
print(cardinality_proportions)
# Print the information
print(extracted_info)
# Close the connection
sink()
# Add name for saving!! This is the data csv print
write.csv(labels, file="Depression_Heart_Failure+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="Depression_Heart_Failure_DBI.csv")
#Script where I load an EHRs document(neuroblastoma) and apply
#the clustering algorithms and my DBI function.
#Then I save everything on a couple of csv files
#I had to get rid of several void rows in the end of the file
#Loading data
mydata<-read.csv("neuroblastoma.csv")
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 3              #radius
minPts<-10           #minimal number of neighbours
#Setting the case
case <- "Neuroblastoma"
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts,case)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Plot the result
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
#Exctract information DBI uses
extracted_info <- extract_clustering_info(mydata, labels)
# Open a connection to a text file
sink("Neuroblastoma_info.txt")
# Print the result
print(highest_DBI_result)
# Print cardinality proportions
print(cardinality_proportions)
# Print the information
print(extracted_info)
# Close the connection
sink()
# Add name for saving!! This is the data csv print
write.csv(labels, file="Neuroblastoma+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="Neuroblastoma_DBI.csv")
#Script where I load an EHRs document(Sepsis) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#Loading data
mydata<-read.csv("Sepsis.csv")
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 20              #radius
minPts<-10            #minimal number of neighbours
#Setting the case
case <- "Sepsis"
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts,case)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Print and plot the result
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
#Exctract information DBI uses
extracted_info <- extract_clustering_info(mydata, labels)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
# Open a connection to a text file
sink("Sepsis_info.txt")
# Print the result
print(highest_DBI_result)
# Print cardinality proportions
print(cardinality_proportions)
# Print the information
print(extracted_info)
# Close the connection
sink()
# Add name for saving!! This is the data csv print
write.csv(labels, file="Sepsis+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="Sepsis_DBI.csv")
#Script where I load an EHRs document(Spain_cardiac_arrest) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#!!I had to delete some rows caused by missing data!!
#(rows: 52 203 221 234 298 391)
#Loading data
mydata<-read.csv("Spain_cardiac_arrest.csv")
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 2.5            #Radius
minPts<-5            #Minimal number of neighbours
#Setting the case
case <- "Cardiac_arrest"
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts,case)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Plot the result
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
#Exctract information DBI uses
extracted_info <- extract_clustering_info(mydata, labels)
# Open a connection to a text file
sink("Spain_cardiac_arrest_info.txt")
# Print the result
print(highest_DBI_result)
# Print cardinality proportions
print(cardinality_proportions)
# Print the information
print(extracted_info)
# Close the connection
sink()
# Add name for saving!! This is the data csv print
write.csv(labels, file="Spain_cardiac_arrest+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="Spain_cardiac_arrest_DBI.csv")
# Assuming you have a dataset called `data`
kNNdistplot(mydata, k = 2) # k is usually set to minPts - 1
abline(h = 25, col = "red") # Manually choose a threshold
abline(h = 25, col = "red") # Manually choose a threshold
abline(h = 5, col = "red") # Manually choose a threshold
kNNdistplot(mydata, k = 5) # k is usually set to minPts - 1
abline(h = 5, col = "red") # Manually choose a threshold
#Script where I load an EHRs document(Spain_cardiac_arrest) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#!!I had to delete some rows caused by missing data!!
#(rows: 52 203 221 234 298 391)
#Loading data
mydata<-read.csv("Spain_cardiac_arrest.csv")
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 5              #Radius
minPts<-6            #Minimal number of neighbours
#Setting the case
case <- "Cardiac_arrest"
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts,case)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
abline(h = 8, col = "red") # Manually choose a threshold
source("~/GitHub/DBI-guide/bin/Cardiac_arrest.R")
kNNdistplot(mydata, k = 4) # k is usually set to minPts - 1
abline(h = 8, col = "red") # Manually choose a threshold
kNNdistplot(mydata, k =6 ) # k is usually set to minPts - 1
abline(h = 8, col = "red") # Manually choose a threshold
abline(h = 10, col = "red") # Manually choose a threshold
source("~/GitHub/DBI-guide/bin/Cardiac_arrest.R")
source("~/GitHub/DBI-guide/bin/Cardiac_arrest.R")
source("~/GitHub/DBI-guide/bin/Cardiac_arrest.R")
source("~/GitHub/DBI-guide/bin/Cardiac_arrest.R")
source("~/GitHub/DBI-guide/bin/Cardiac_arrest.R")
#Script where I load an EHRs document(Spain_cardiac_arrest) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#!!I had to delete some rows caused by missing data!!
#(rows: 52 203 221 234 298 391)
#Loading data
mydata<-read.csv("Spain_cardiac_arrest.csv")
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 3              #Radius
minPts<-6            #Minimal number of neighbours
#Setting the case
case <- "Cardiac_arrest"
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts,case)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Plot the result
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
#Exctract information DBI uses
extracted_info <- extract_clustering_info(mydata, labels)
# Open a connection to a text file
sink("Spain_cardiac_arrest_info.txt")
# Print the result
print(highest_DBI_result)
# Print cardinality proportions
print(cardinality_proportions)
# Print the information
print(extracted_info)
# Close the connection
sink()
# Add name for saving!! This is the data csv print
write.csv(labels, file="Spain_cardiac_arrest+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="Spain_cardiac_arrest_DBI.csv")
installed_packages <- installed.packages()[, "Package"]
for (pkg in installed_packages) { suppressPackageStartupMessages(library(pkg, character.only = TRUE)) }
library(translations, lib.loc = "C:/Program Files/R/R-4.3.3/library")
source("~/GitHub/DBI-guide/bin/find_best_parameters.R")
source("~/GitHub/DBI-guide/bin/Cardiac_arrest.R")
names(highest_DBI_result)
source("~/GitHub/DBI-guide/bin/find_best_parameters.R")
source("~/GitHub/DBI-guide/bin/Cardiac_arrest.R")

plot_cluster_flow(my data, kmeans_result_2,kmeans_result_3)
plot_cluster_flow(mydata, kmeans_result_2,kmeans_result_3)
View(kmeans_result_2)
class(kmeans_result_2)
source("~/GitHub/DBI-guide/bin/plot_cluster_flow.R")
plot_cluster_flow(mydata, kmeans_result_2,kmeans_result_3)
sample_data <- matrix(rnorm(100), nrow = 20, ncol = 5)
labels1 <- sample(1:3, 20, replace = TRUE)
class(labels1)
source("~/GitHub/DBI-guide/bin/plot_cluster_flow.R")
plot_cluster_flow(mydata, kmeans_result_2,kmeans_result_3)
source("~/GitHub/DBI-guide/bin/plot_cluster_flow.R")
plot_cluster_flow(mydata, kmeans_result_2,kmeans_result_3)
View(labels)
View(kmeans_result)
View(labels)
labels[[2],"kmeans_result_2"]
labels["kmeans_result_2"]
labels[[2]]
labels[[2]]$kmeans_result_2
source("~/GitHub/DBI-guide/bin/plot_cluster_flow.R")
plot_cluster_flow(mydata, labels[[2]]$kmeans_result_2,labels[[2]]$kmeans_result_3)
source("~/GitHub/DBI-guide/bin/plot_cluster_flow.R")
plot_cluster_flow(mydata, labels[[2]]$kmeans_result_2,labels[[2]]$kmeans_result_3)
source("~/GitHub/DBI-guide/bin/plot_cluster_flow.R")
plot_cluster_flow(mydata, labels[[2]]$kmeans_result_2,labels[[2]]$kmeans_result_3)
source("~/GitHub/DBI-guide/bin/plot_cluster_flow.R")
plot_cluster_flow(mydata, labels[[2]]$kmeans_result_2,labels[[2]]$kmeans_result_3)
class(labels[[2]]$kmeans_result_2)
class(mydata)
source("~/GitHub/DBI-guide/bin/plot_cluster_flow.R")
plot_cluster_flow(mydata, labels[[2]]$kmeans_result_2,labels[[2]]$kmeans_result_3)
source("~/GitHub/DBI-guide/bin/plot_cluster_flow.R")
plot_cluster_flow(mydata, labels[[2]]$kmeans_result_2,labels[[2]]$kmeans_result_3)
source("~/GitHub/DBI-guide/bin/plot_cluster_flow.R")
plot_cluster_flow(mydata, labels[[2]]$kmeans_result_2,labels[[2]]$kmeans_result_3)
source("~/GitHub/DBI-guide/bin/plot_cluster_flow.R")
plot_cluster_flow(mydata, labels[[2]]$kmeans_result_2,labels[[2]]$kmeans_result_3)
View(cardinality_proportions)
source("~/GitHub/DBI-guide/bin/plot_cluster_percentages.R")
plot_cluster_percentages(cardinality_proportions)
source("~/GitHub/DBI-guide/bin/plot_cluster_percentages.R")
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
plot_cluster_percentages(cardinality_proportions)
# Example function to calculate percentages (similar to your previous function)
calculate_cardinality_proportion <- function(data, km_labels, hc_labels, dbsc_lab) {
total_elements <- nrow(data)
calculate_percentages <- function(clusters) {
cluster_sizes <- table(clusters)
cluster_percentages <- (cluster_sizes / total_elements) * 100
return(cluster_percentages)
}
# Calculate percentages for K-means
kmeans2_percentages <- calculate_percentages(km_labels$kmeans_result_2)
kmeans3_percentages <- calculate_percentages(km_labels$kmeans_result_3)
kmeans5_percentages <- calculate_percentages(km_labels$kmeans_result_5)
# Calculate percentages for hierarchical clustering
hc_ave_percentages <- calculate_percentages(hc_labels$labels_average)
hc_comp_percentages <- calculate_percentages(hc_labels$labels_complete)
hc_sing_percentages <- calculate_percentages(hc_labels$labels_single)
# Calculate percentages for DBSCAN
dbscan_smal_percentages <- calculate_percentages(dbsc_lab$dbscan_smal)
dbscan_med_percentages <- calculate_percentages(dbsc_lab$dbscan_med)
dbscan_big_percentages <- calculate_percentages(dbsc_lab$dbscan_big)
# Combine results into a list
percentages <- list(
kmeans2 = kmeans2_percentages,
kmeans3 = kmeans3_percentages,
kmeans5 = kmeans5_percentages,
hc_ave = hc_ave_percentages,
hc_comp = hc_comp_percentages,
hc_sing = hc_sing_percentages,
dbscan_smal = dbscan_smal_percentages,
dbscan_med = dbscan_med_percentages,
dbscan_big = dbscan_big_percentages
)
return(percentages)
}
# Function to extract percentages of cluster 0 (outliers) from DBSCAN results
extract_outlier_percentages <- function(dbscan_results) {
outlier_percentages <- lapply(dbscan_results, function(dbscan_result) {
outliers <- sum(dbscan_result == 0)  # Count outliers (cluster 0)
total <- length(dbscan_result)
return(outliers / total * 100)  # Calculate percentage
})
return(outlier_percentages)
}
# Function to create bar chart of outlier percentages across clustering algorithms
plot_outlier_percentages <- function(percentages) {
dbscan_percentages <- percentages[c("dbscan_smal", "dbscan_med", "dbscan_big")]
outlier_percentages <- extract_outlier_percentages(dbscan_percentages)
# Convert to data frame for plotting
df <- data.frame(
Algorithm = rep(c("DBSCAN Small", "DBSCAN Medium", "DBSCAN Large"), each = 8),
Clustering_Algorithm = rep(names(percentages)[-c(7:9)], times = 3),
Outlier_Percentage = unlist(outlier_percentages)
)
# Create the bar chart
ggplot(df, aes(x = Clustering_Algorithm, y = Outlier_Percentage, fill = Algorithm)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Clustering Algorithm", y = "Percentage of Outliers (%)",
fill = "DBSCAN Algorithm",
title = "Percentage of Outliers (Cluster 0) Across Clustering Algorithms") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
# Example usage with hypothetical data
# Simulate clustering results
set.seed(123)
km_labels <- list(
kmeans_result_2 = sample(0:1, 100, replace = TRUE),
kmeans_result_3 = sample(0:2, 100, replace = TRUE),
kmeans_result_5 = sample(0:4, 100, replace = TRUE)
)
hc_labels <- list(
labels_average = sample(0:1, 100, replace = TRUE),
labels_complete = sample(0:2, 100, replace = TRUE),
labels_single = sample(0:4, 100, replace = TRUE)
)
dbsc_lab <- list(
dbscan_smal = sample(0:1, 100, replace = TRUE),
dbscan_med = sample(0:2, 100, replace = TRUE),
dbscan_big = sample(0:4, 100, replace = TRUE)
)
# Calculate percentages for all clustering algorithms
percentages <- calculate_cardinality_proportion(NULL, km_labels, hc_labels, dbsc_lab)
# Call the function to create the bar chart
plot_outlier_percentages(percentages)
# Example usage with hypothetical data
# Simulate clustering results
set.seed(123)
km_labels <- list(
kmeans_result_2 = sample(0:1, 100, replace = TRUE),
kmeans_result_3 = sample(0:2, 100, replace = TRUE),
kmeans_result_5 = sample(0:4, 100, replace = TRUE)
)
hc_labels <- list(
labels_average = sample(0:1, 100, replace = TRUE),
labels_complete = sample(0:2, 100, replace = TRUE),
labels_single = sample(0:4, 100, replace = TRUE)
)
dbsc_lab <- list(
dbscan_smal = sample(0:1, 100, replace = TRUE),
dbscan_med = sample(0:2, 100, replace = TRUE),
dbscan_big = sample(0:4, 100, replace = TRUE)
)
# Calculate percentages for all clustering algorithms
percentages <- calculate_cardinality_proportion(NULL, km_labels, hc_labels, dbsc_lab)
# Call the function to create the bar chart
plot_outlier_percentages(percentages)
source("~/GitHub/DBI-guide/bin/clust_info.R")
clust_info(mydata,labels[[2]]$kmeans_result_2)
plot_cluster_percentages(cardinality_proportions)
compare_clusterings(labels)
print(cardinality_proportions)
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
clust_info(mydata,labels[[2]]$kmeans_result_2)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
class(labels[[i]]$kmeans_result_2)
class(labels[[2]]$kmeans_result_2)
cluster_labels <- labels[[2]]$kmeans_result_2
class
class(cluster_labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
for (i in 1:length(labels))
{
# Initialize cluster_labels based on i
cluster_labels <- NULL
# Inner loop and switch case to handle different label types
for (j in 1:length(labels[[i]])) {
# Switch case to assign appropriate cluster labels
switch(i,
"1" = {  # Case for kmeans_result_2
if (j == 1) {
cluster_labels <- labels[[i]]$kmeans_result_2
} else if (j == 2) {
cluster_labels <- labels[[i]]$kmeans_result_3
} else if (j == 3) {
cluster_labels <- labels[[i]]$kmeans_result_5
}
},
"2" = {  # Case for hc_labels (adjust as per your actual structure)
if (j == 1) {
cluster_labels <- labels[[i]]$labels_average
} else if (j == 2) {
cluster_labels <- labels[[i]]$labels_complete
} else if (j == 3) {
cluster_labels <- labels[[i]]$labels_single
}
},
"3" = {  # Case for dbsc_lab (adjust as per your actual structure)
if (j == 1) {
cluster_labels <- labels[[i]]$dbscan_smal
} else if (j == 2) {
cluster_labels <- labels[[i]]$dbscan_med
} else if (j == 3) {
cluster_labels <- labels[[i]]$dbscan_big
}
}
)
# Calculate cluster information
# Example calculations, adjust as per your actual function or data structure
scatter_data <- clust_info(data, cluster_labels)
# Store results in a named list
algorithm_name <- paste0("Algorithm_", i, "_", j)
cluster_info[[algorithm_name]] <- scatter_data
}
}
cluster_labels <- NULL
for (j in 1:length(labels[[i]])) {
# Switch case to assign appropriate cluster labels
switch(i,
"1" = {  # Case for kmeans_result_2
if (j == 1) {
cluster_labels <- labels[[i]]$kmeans_result_2
} else if (j == 2) {
cluster_labels <- labels[[i]]$kmeans_result_3
} else if (j == 3) {
cluster_labels <- labels[[i]]$kmeans_result_5
}
},
"2" = {  # Case for hc_labels (adjust as per your actual structure)
if (j == 1) {
cluster_labels <- labels[[i]]$labels_average
} else if (j == 2) {
cluster_labels <- labels[[i]]$labels_complete
} else if (j == 3) {
cluster_labels <- labels[[i]]$labels_single
}
},
"3" = {  # Case for dbsc_lab (adjust as per your actual structure)
if (j == 1) {
cluster_labels <- labels[[i]]$dbscan_smal
} else if (j == 2) {
cluster_labels <- labels[[i]]$dbscan_med
} else if (j == 3) {
cluster_labels <- labels[[i]]$dbscan_big
}
}
)
# Calculate cluster information
# Example calculations, adjust as per your actual function or data structure
scatter_data <- clust_info(data, cluster_labels)
# Store results in a named list
algorithm_name <- paste0("Algorithm_", i, "_", j)
cluster_info[[algorithm_name]] <- scatter_data
}
if (j == 1) {
cluster_labels <- labels[[i]]$kmeans_result_2
} else if (j == 2) {
cluster_labels <- labels[[i]]$kmeans_result_3
} else if (j == 3) {
cluster_labels <- labels[[i]]$kmeans_result_5
}
i=1
j=1
if (j == 1) {
cluster_labels <- labels[[i]]$kmeans_result_2
} else if (j == 2) {
cluster_labels <- labels[[i]]$kmeans_result_3
} else if (j == 3) {
cluster_labels <- labels[[i]]$kmeans_result_5
}
view(labels)
#Script where I load an EHRs document(depression_heart_failure) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#I had to get rid of id column since it didnt make any sense with the clustering
#Loading data
mydata0<-read.csv("depression_heart_failure.csv")
#Getting rid of id column
mydata<-mydata0[,2:ncol(mydata0)]
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 50              #radius
minPts<-10            #minimal number of neighbours
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
# Print the result
print(highest_DBI_result)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Print and plot the result
print(cardinality_proportions)
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
compare_clusterings(labels)
compare_clusterings(labels)
extracted_info <- extract_clustering_info(mydata, labels)
View(labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
for (i in 2:length(labels)) {
# Initialize cluster_labels based on i
cluster_labels <- NULL
# Inner loop and switch case to handle different label types
for (j in 1:length(labels[[i]])) {
# Switch case to assign appropriate cluster labels
switch(i,
"1" = {  # Case for kmeans_result_2
if (j == 1) {
cluster_labels <- labels[[i]]$kmeans_result_2
} else if (j == 2) {
cluster_labels <- labels[[i]]$kmeans_result_3
} else if (j == 3) {
cluster_labels <- labels[[i]]$kmeans_result_5
}
},
"2" = {  # Case for hc_labels (adjust as per your actual structure)
if (j == 1) {
cluster_labels <- labels[[i]]$labels_average
} else if (j == 2) {
cluster_labels <- labels[[i]]$labels_complete
} else if (j == 3) {
cluster_labels <- labels[[i]]$labels_single
}
},
"3" = {  # Case for dbsc_lab (adjust as per your actual structure)
if (j == 1) {
cluster_labels <- labels[[i]]$dbscan_smal
} else if (j == 2) {
cluster_labels <- labels[[i]]$dbscan_med
} else if (j == 3) {
cluster_labels <- labels[[i]]$dbscan_big
}
}
)
# Calculate cluster information
# Example calculations, adjust as per your actual function or data structure
scatter_data <- clust_info(data, cluster_labels)
# Store results in a named list
algorithm_name <- paste0("Algorithm_", i, "_", j)
cluster_info[[algorithm_name]] <- scatter_data
}
}
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
extracted_info <- extract_clustering_info( labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
source("~/GitHub/DBI-guide/bin/extract_cluster_metrics.R")
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
#Script where I load an EHRs document(depression_heart_failure) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#I had to get rid of id column since it didnt make any sense with the clustering
#Loading data
mydata0<-read.csv("depression_heart_failure.csv")
#Getting rid of id column
mydata<-mydata0[,2:ncol(mydata0)]
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 50              #radius
minPts<-10            #minimal number of neighbours
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
# Print the result
print(highest_DBI_result)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Print and plot the result
print(cardinality_proportions)
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
extracted_info <- extract_clustering_info(mydata, labels)
data<-mydata
metrics_kmeans2 <- extract_cluster_metrics(data, labels[[2]]$kmeans_result_2)
metrics_kmeans3 <- extract_cluster_metrics(data, labels[[2]]$kmeans_result_3)
metrics_kmeans5 <- extract_cluster_metrics(data, labels[[2]]$kmeans_result_5)
metrics_hc_ave <- extract_cluster_metrics(data, labels[[3]]$labels_average)
metrics_hc_comp <- extract_cluster_metrics(data, labels[[3]]$labels_complete)
metrics_hc_sing <- extract_cluster_metrics(data, labels[[3]]$labels_single)
metrics_dbscan_smal <- extract_cluster_metrics(data, labels[[4]]$dbscan_smal)
View(labels)
labels[[4]]
View(labels)
metrics_dbscan_smal <- extract_cluster_metrics(data, labels[[4]]$dbscan_smal)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
source("~/GitHub/DBI-guide/bin/extract_clustering_info.R")
extracted_info <- extract_clustering_info(mydata, labels)
View(extracted_info)
source("~/GitHub/DBI-guide/bin/Depression_HeartFailure.R")
#Script where I load an EHRs document(depression_heart_failure) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#I had to get rid of id column since it didnt make any sense with the clustering
#Loading data
mydata0<-read.csv("depression_heart_failure.csv")
#Getting rid of id column
mydata<-mydata0[,2:ncol(mydata0)]
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 50              #radius
minPts<-10            #minimal number of neighbours
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
# Print the result
print(highest_DBI_result)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Compare clusterings in a chart
compare_clusterings(labels)
extracted_info <- extract_clustering_info(mydata, labels)
# Add name for saving!! This is the info csv print
write.csv(extracted_info, file="depression_heart_failure_info.csv")
writeLines(extracted_info, file="depression_heart_failure_info.csv")
writeLines(extracted_info, file="depression_heart_failure_info.csv")
writeLines(extracted_info, file.path="depression_heart_failure_info.csv")
writeLines(extracted_info, filepath="depression_heart_failure_info.csv")
writeLines(my_variable=extracted_info, file_path="depression_heart_failure_info.csv")
writeLines(my_variable=extracted_info, file_path="depression_heart_failure_info.txt")
cat(my_variable=extracted_info, file_path="depression_heart_failure_info.txt", append = FALSE)
write.csv(do.call(rbind, extracted_info), file = "depression_heart_failure_info.csv", row.names = FALSE)
max_length <- max(lengths(extracted_info))
# Pad shorter rows with NA to match the maximum length
extracted_info_padded <- map(extracted_info, ~ c(.x, rep(NA, max_length - length(.x))))
# Add name for saving!! This is the info csv print
write.csv(do.call(rbind, extracted_info), file = "depression_heart_failure_info.csv", row.names = FALSE)
# Determine the maximum length of the list elements
max_length <- max(lengths(extracted_info))
# Pad shorter rows with NA to match the maximum length
extracted_info_padded <- map(extracted_info, ~ c(.x, rep(NA, max_length - length(.x))))
# Add name for saving!! This is the info csv print
write.csv(as.data.frame(do.call(cbind, extracted_info_padded)), "depression_heart_failure_info.csv", row.names = FALSE)
source("~/GitHub/DBI-guide/bin/Depression_HeartFailure.R")
write.csv(extracted_info, file = "depression_heart_failure_info.csv", row.names = FALSE)
write.csv(extracted_info, file = "depression_heart_failure_info.csv", row.names = FALSE, col.names=FALSE)
write.table(extracted_info, file="depression_heart_failure_info.csv", sep = "\t", row.names = FALSE)
extracted_info <- extract_clustering_info(mydata, labels)
write.table(extracted_info, file="depression_heart_failure_info.csv", sep = "\t", row.names = FALSE)
write.table(extracted_info, file="depression_heart_failure_info.txt", sep = "\t", row.names = FALSE)
print(extracted_info)
source("~/GitHub/DBI-guide/bin/Depression_HeartFailure.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
dim<-50      #<------
#Number of vectors
num<-2*dim
# Creating the initial dataset, vectors are columns
zeros <- matrix(0, ncol = dim, nrow = dim)
ones <- matrix(1, ncol = dim, nrow = dim)
data <- rbind(zeros, ones)
# Initial kmeans and Davies-Bouldin index calculation
kmeans_result <- kmeans(data, centers = 2)
metrics<-extract_cluster_metrics(data,kmeans_result$cluster)
View(metrics)
clust_info(data, kmeans_result$cluster)
help(cls.scatt.data)
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/extract_cluster_metrics.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/extract_cluster_metrics.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/extract_cluster_metrics.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")

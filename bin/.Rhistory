#Compare clusterings in a chart
compare_clusterings(labels)
extracted_info <- extract_clustering_info(mydata, labels)
# Add name for saving!! This is the info csv print
write.csv(extracted_info, file="depression_heart_failure_info.csv")
writeLines(extracted_info, file="depression_heart_failure_info.csv")
writeLines(extracted_info, file="depression_heart_failure_info.csv")
writeLines(extracted_info, file.path="depression_heart_failure_info.csv")
writeLines(extracted_info, filepath="depression_heart_failure_info.csv")
writeLines(my_variable=extracted_info, file_path="depression_heart_failure_info.csv")
writeLines(my_variable=extracted_info, file_path="depression_heart_failure_info.txt")
cat(my_variable=extracted_info, file_path="depression_heart_failure_info.txt", append = FALSE)
write.csv(do.call(rbind, extracted_info), file = "depression_heart_failure_info.csv", row.names = FALSE)
max_length <- max(lengths(extracted_info))
# Pad shorter rows with NA to match the maximum length
extracted_info_padded <- map(extracted_info, ~ c(.x, rep(NA, max_length - length(.x))))
# Add name for saving!! This is the info csv print
write.csv(do.call(rbind, extracted_info), file = "depression_heart_failure_info.csv", row.names = FALSE)
# Determine the maximum length of the list elements
max_length <- max(lengths(extracted_info))
# Pad shorter rows with NA to match the maximum length
extracted_info_padded <- map(extracted_info, ~ c(.x, rep(NA, max_length - length(.x))))
# Add name for saving!! This is the info csv print
write.csv(as.data.frame(do.call(cbind, extracted_info_padded)), "depression_heart_failure_info.csv", row.names = FALSE)
source("~/GitHub/DBI-guide/bin/Depression_HeartFailure.R")
write.csv(extracted_info, file = "depression_heart_failure_info.csv", row.names = FALSE)
write.csv(extracted_info, file = "depression_heart_failure_info.csv", row.names = FALSE, col.names=FALSE)
write.table(extracted_info, file="depression_heart_failure_info.csv", sep = "\t", row.names = FALSE)
extracted_info <- extract_clustering_info(mydata, labels)
write.table(extracted_info, file="depression_heart_failure_info.csv", sep = "\t", row.names = FALSE)
write.table(extracted_info, file="depression_heart_failure_info.txt", sep = "\t", row.names = FALSE)
print(extracted_info)
source("~/GitHub/DBI-guide/bin/Depression_HeartFailure.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
dim<-50      #<------
#Number of vectors
num<-2*dim
# Creating the initial dataset, vectors are columns
zeros <- matrix(0, ncol = dim, nrow = dim)
ones <- matrix(1, ncol = dim, nrow = dim)
data <- rbind(zeros, ones)
# Initial kmeans and Davies-Bouldin index calculation
kmeans_result <- kmeans(data, centers = 2)
metrics<-extract_cluster_metrics(data,kmeans_result$cluster)
View(metrics)
clust_info(data, kmeans_result$cluster)
help(cls.scatt.data)
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/extract_cluster_metrics.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/extract_cluster_metrics.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/extract_cluster_metrics.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Depression_HeartFailure.R")
source("~/GitHub/DBI-guide/bin/Cardiac_arrest.R")
source("~/GitHub/DBI-guide/bin/Neuroblastoma.R")
source("~/GitHub/DBI-guide/bin/Diabetes.R")
source("~/GitHub/DBI-guide/bin/Sepsis.R")
installed_packages <- installed.packages()[, "Package"]
for (pkg in installed_packages) { suppressPackageStartupMessages(library(pkg, character.only = TRUE)) }
source("~/GitHub/DBI-guide/bin/Depression_HeartFailure.R")
library(translations, lib.loc = "C:/Program Files/R/R-4.3.3/library")
source("~/GitHub/DBI-guide/bin/Depression_HeartFailure.R")
source("~/GitHub/DBI-guide/bin/plot_cluster_percentages.R")
source("~/GitHub/DBI-guide/bin/Depression_HeartFailure.R")
plot_cluster_percentages(cardinality_proportions)
compare_clusterings(labels)
source("~/GitHub/DBI-guide/bin/dbscan_labels.R")
source("~/GitHub/DBI-guide/bin/Cardiac_arrest.R")
source("~/GitHub/DBI-guide/bin/Cardiac_arrest.R")
#Script where I load an EHRs document(depression_heart_failure) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#I had to get rid of id column since it didnt make any sense with the clustering
#Loading data
mydata0<-read.csv("depression_heart_failure.csv")
#Getting rid of id column
mydata<-mydata0[,2:ncol(mydata0)]
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 50              #radius
minPts<-10            #minimal number of neighbours
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
# Print the result
print(highest_DBI_result)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Print and plot the result
print(cardinality_proportions)
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
#Exctract information DBI uses
extracted_info <- extract_clustering_info(mydata, labels)
# check the information
print(extracted_info)
# Add name for saving!! This is the data csv print
write.csv(labels, file="depression_heart_failure+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="depression_heart_failure_DBI.csv")
View(extracted_info)
View(extracted_info)
View(extracted_info)
help(sink)
sink(file = NULL, append = FALSE, type = c("exctracted_info", "message"),
split = FALSE)
sink(file = tt.txt, append = FALSE, type = c("exctracted_info", "message"),  split = FALSE)
source("~/GitHub/DBI-guide/bin/dbscan_labels.R")
source("~/GitHub/DBI-guide/bin/dbscan_labels.R")
source("~/GitHub/DBI-guide/bin/Sepsis.R")
source("~/GitHub/DBI-guide/bin/Sepsis.R")
compare_clusterings(labels)
source("~/GitHub/DBI-guide/bin/Cardiac_arrest.R")
source("~/GitHub/DBI-guide/bin/Depression_HeartFailure.R")
source("~/GitHub/DBI-guide/bin/Neuroblastoma.R")
source("~/GitHub/DBI-guide/bin/Diabetes.R")
source("~/GitHub/DBI-guide/bin/Sepsis.R")
source("~/GitHub/DBI-guide/bin/Cardiac_arrest.R")
#Script where I load an EHRs document(Spain_cardiac_arrest) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#!!I had to delete some rows caused by missing data!!
#(rows: 52 203 221 234 298 391)
#Loading data
mydata<-read.csv("Spain_cardiac_arrest.csv")
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 2.5            #Radius
minPts<-5            #Minimal number of neighbours
#Setting the case
case <- "Cardiac_arrest"
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts,case)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Plot the result
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
#Exctract information DBI uses
extracted_info <- extract_clustering_info(mydata, labels)
# Open a connection to a text file
sink("Spain_cardiac_arrest_info.txt")
# Print the result
print(highest_DBI_result)
# Print cardinality proportions
print(cardinality_proportions)
# Print the information
print(extracted_info)
# Close the connection
sink()
# Add name for saving!! This is the data csv print
write.csv(labels, file="Spain_cardiac_arrest+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="Spain_cardiac_arrest_DBI.csv")
source("~/GitHub/DBI-guide/bin/Depression_HeartFailure.R")
#Script where I load an EHRs document(depression_heart_failure) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#I had to get rid of id column since it didnt make any sense with the clustering
#Loading data
mydata0<-read.csv("depression_heart_failure.csv")
#Getting rid of id column
mydata<-mydata0[,2:ncol(mydata0)]
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 50              #radius
minPts<-10            #minimal number of neighbours
#Setting the case
case <- "Heart_failure"
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts,case)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Plot the result
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
#Exctract information DBI uses
extracted_info <- extract_clustering_info(mydata, labels)
# Open a connection to a text file
sink("Depression_Heart_Failure_info.txt")
# Print the result
print(highest_DBI_result)
# Print cardinality proportions
print(cardinality_proportions)
# Print the information
print(extracted_info)
# Close the connection
sink()
# Add name for saving!! This is the data csv print
write.csv(labels, file="Depression_Heart_Failure+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="Depression_Heart_Failure_DBI.csv")
source("~/GitHub/DBI-guide/bin/Sepsis.R")
#Script where I load an EHRs document(Sepsis) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#Loading data
mydata<-read.csv("Sepsis.csv")
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 20              #radius
minPts<-10            #minimal number of neighbours
#Setting the case
case <- "Sepsis"
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts,case)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Print and plot the result
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
#Exctract information DBI uses
extracted_info <- extract_clustering_info(mydata, labels)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
# Open a connection to a text file
sink("Sepsis_info.txt")
# Print the result
print(highest_DBI_result)
# Print cardinality proportions
print(cardinality_proportions)
# Print the information
print(extracted_info)
# Close the connection
sink()
# Add name for saving!! This is the data csv print
write.csv(labels, file="Sepsis+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="Sepsis_DBI.csv")
source("~/GitHub/DBI-guide/bin/Neuroblastoma.R")
#Script where I load an EHRs document(neuroblastoma) and apply
#the clustering algorithms and my DBI function.
#Then I save everything on a couple of csv files
#I had to get rid of several void rows in the end of the file
#Loading data
mydata<-read.csv("neuroblastoma.csv")
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 3              #radius
minPts<-10           #minimal number of neighbours
#Setting the case
case <- "Neuroblastoma"
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts,case)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Plot the result
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
#Exctract information DBI uses
extracted_info <- extract_clustering_info(mydata, labels)
# Open a connection to a text file
sink("Neuroblastoma_info.txt")
# Print the result
print(highest_DBI_result)
# Print cardinality proportions
print(cardinality_proportions)
# Print the information
print(extracted_info)
# Close the connection
sink()
# Add name for saving!! This is the data csv print
write.csv(labels, file="Neuroblastoma+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="Neuroblastoma_DBI.csv")
source("~/GitHub/DBI-guide/bin/Diabetes.R")
#Script where I load an EHRs document(diabetes_type1) and apply the kmeans clustering
#and my DBI function. Then I save everything on a couple of csv files
#Loading data
mydata<-read.csv("diabetes_type1.csv")
#getting kmeans labels
km_labels<-kmeans_labels(mydata)
#getting hclust labels
hc_labels<-hclust_labels(mydata)
#Getting dbscan parameters
eps<- 25               #radius
minPts<-2             #minimal number of neighbours
#Setting the case
case <- "Diabetes"
#getting dbscan labels
dbsc_lab<-dbscan_labels(mydata,eps,minPts,case)
# Calculate the four indexes
indexes<-DBI_EHRs(mydata,km_labels,hc_labels,dbsc_lab)
#binding clusterings for printing
labels<-list(mydata,km_labels,hc_labels,dbsc_lab)
#Find the highest DBI scores
highest_DBI_result <- find_highest_DBI(indexes)
#Calculate cardinality of clusters
cardinality_proportions <- calculate_cardinality_proportion(mydata,km_labels,hc_labels,dbsc_lab)
#Plot the result
plot_cluster_percentages(cardinality_proportions)
#Compare clusterings in a chart
compare_clusterings(labels)
#Exctract information DBI uses
extracted_info <- extract_clustering_info(mydata, labels)
# Open a connection to a text file
sink("Diabetes_type1_info.txt")
# Print the result
print(highest_DBI_result)
# Print cardinality proportions
print(cardinality_proportions)
# Print the information
print(extracted_info)
# Close the connection
sink()
# Add name for saving!! This is the data csv print
write.csv(labels, file="Diabetes_type1+labels.csv")
# Add name for saving!! This is the DBI evaluation csv print
write.csv(indexes, file="Diabetes_type1_DBI.csv")
compare_clusterings(labels)
compare_clusterings(labels)
compare_clusterings(labels)
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Growing_kmeans_matrix.R")
#Script where a matrix with N ones N-dimensional vectors
#and N zero N-dimensional vectors representing the data points
#get modifyed 2N-times alternating to ones and zeros, with a random
#N-dimensional vector between zero and one.
#At each step a clustering with kmeans and the DBI evaluation
#Arrows point where to modify at each change
#In this version k_means changes number of centers as the changes grow
#Number of dimensions
dim<-20      #<------
#Number of vectors
num<-2*dim
# Creating the initial dataset, vectors are columns
zeros <- matrix(0, ncol = dim, nrow = dim)
ones <- matrix(1, ncol = dim, nrow = dim)
data <- rbind(zeros, ones)
# Initial kmeans and Davies-Bouldin index calculation
kmeans_result <- kmeans(data, centers = 2)
db_indices <- data.frame(t(DBI(data, kmeans_result$cluster)))
# Store the metrics
metrics<-extract_cluster_metrics(data,kmeans_result$cluster)
metrics_store <- data.frame(
Step = 0,
metrics
)
# Store the results
results <- data.frame(
Step = 0,
DB_Index_Avg = db_indices$average,
DB_Index_Centroid = db_indices$centroid,
Norm_DB_Index_Avg = db_indices$norm_ave,
Norm_DB_Index_Centroid = db_indices$norm_cent
)
# Store the data
data_store<-data.frame(
Step=0,
data
)
#Store k-means
kmeans_store<-data.frame(
Step=0,
kmeans_result$cluster
)
# Function to generate a random vector in the given dimension
random_vector <- function() {
runif(dim, 0, 1)
}
# Modify vectors in a cyclic manner
for (i in 1:num)
{
#Alternating cluster modyfied
if (i %% 2 == 1)
{
data[(i + 1) / 2, ] <- random_vector()
}
else
{
data[dim + i / 2, ] <- random_vector()
}
#kmeans and DBI execution at each step
kmeans_result <- kmeans(data, centers = 2+ceiling(i/2), iter.max=30)
db_indices <- data.frame(t(DBI(data, kmeans_result$cluster)))
#Store results
results <- rbind(results, data.frame(
Step = i,
DB_Index_Avg = db_indices$average,
DB_Index_Centroid = db_indices$centroid,
Norm_DB_Index_Avg = db_indices$norm_ave,
Norm_DB_Index_Centroid = db_indices$norm_cent
))
#Store data
data_store <- rbind(data_store, data.frame(
Step = i,
data
))
#Store k-means results
kmeans_store <- rbind(kmeans_store, data.frame(
Step = i,
kmeans_result$cluster
))
#Store metrics
metrics<-extract_cluster_metrics(data,kmeans_result$cluster)
metrics_store<- rbind(metrics_store, data.frame(
Step = i,
metrics
))
}
source("~/GitHub/DBI-guide/bin/Growing_kmeans_matrix.R")
source("~/GitHub/DBI-guide/bin/Growing_kmeans_matrix.R")
source("~/GitHub/DBI-guide/bin/Growing_kmeans_matrix.R")
source("~/GitHub/DBI-guide/bin/Growing_kmeans_matrix.R")
source("~/GitHub/DBI-guide/bin/Growing_kmeans_matrix.R")
source("~/GitHub/DBI-guide/bin/Growing_kmeans_matrix.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Growing_kmeans_matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
random_vector <- function() {
runif(dim, 0, 1)
}
View(random_vector)
d<-random_vector
d<-random_vector ()
d
zeros <- matrix(0, ncol = dim, nrow = num/2)
ones <- matrix(1, ncol = dim, nrow = num/2)
data <- rbind(zeros, ones)
data
kmeans_result <- kmeans(data, centers = 2)
kmeans_result
db_indices <- data.frame(t(DBI(data, kmeans_result$cluster)))
db_indices
# Store the metrics
metrics<-extract_cluster_metrics(data,kmeans_result$cluster)
metrics_store <- data.frame(
Step = 0,
metrics
)
# Store the metrics
metrics
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
View(kmeans_store)
# Save on csv all the results
file_name_dbi <- paste0(num, "_Vectors_", dim, "Dimensions_Matrix_DBI.csv")
write.csv(results, file = file_name_dbi)
file_name_data <- paste0(num, "_Vectors_", dim, "Dimensions_Matrix_data.csv")
write.csv(data_store, file = file_name_data)
file_name_kmeans <- paste0(num, "_Vectors_", dim, "Dimensions_Matrix_kmeans.csv")
write.csv(kmeans_store, file = file_name_kmeans)
file_name_metrics <- paste0(num, "_Vectors_", dim, "Dimensions_Matrix_metrics.csv")
write.csv(metrics_store, file = file_name_metrics)
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Growing_kmeans_matrix.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Zero_Ones_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
source("~/GitHub/DBI-guide/bin/Num_Vectors_Dim_Dimensions_Matrix.R")
